{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing Images \nfrom IPython.display import Image\nimport os\n!ls ../input/logisticr","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:33.181894Z","iopub.execute_input":"2022-06-29T14:57:33.182425Z","iopub.status.idle":"2022-06-29T14:57:33.955455Z","shell.execute_reply.started":"2022-06-29T14:57:33.182344Z","shell.execute_reply":"2022-06-29T14:57:33.954030Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing Images \nfrom IPython.display import Image\nimport os\n!ls ../input/lgrfff","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:33.958325Z","iopub.execute_input":"2022-06-29T14:57:33.958857Z","iopub.status.idle":"2022-06-29T14:57:34.725605Z","shell.execute_reply.started":"2022-06-29T14:57:33.958801Z","shell.execute_reply":"2022-06-29T14:57:34.724305Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"The ***purpose*** of this project is to discuss the concept behind the Logistic Regression model and to build a Multi-Class Logistic Regression Classifier for classifying plant species based on features of the plants. ","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"This a classification algorithm which is based on the Log-function wherein the output can be 1 or 0. It can be treated as a binary classifier(Predicts if the input is true/false based on a class) problem but can be extended to a multiclass classification problem. It can take both discrete and continous data as features. We see what features help in getting a prediction other than 0, if it does not; then we remove those specific features.\n\nIn the case of binary classification, based on an input x; if the value returned by the model is closer to 0, it is then given a negative label. Else, it is given a positive label.  \n\nIn the case of Multi-Class classification, the output is not true or false; the output can be characterized in labels representing different categories. Logistic regression is usually not used for Multi-Class Classification. \n\nThe model looks like the following with parts of it coming from linear regression","metadata":{}},{"cell_type":"code","source":"Image(\"../input/logisticr/lgr.png\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:34.728415Z","iopub.execute_input":"2022-06-29T14:57:34.728967Z","iopub.status.idle":"2022-06-29T14:57:34.770278Z","shell.execute_reply.started":"2022-06-29T14:57:34.728911Z","shell.execute_reply":"2022-06-29T14:57:34.769087Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Figure 1. Logistic Regression Model","metadata":{}},{"cell_type":"markdown","source":"The output is basically a probability of the class of x being positive based on threshold. The maximum likeliheed optimization criterion is used and we use the log-likelihood as shown in figure 2:","metadata":{}},{"cell_type":"code","source":"Image(\"../input/lgrfff/lgrf.png\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:34.772593Z","iopub.execute_input":"2022-06-29T14:57:34.773180Z","iopub.status.idle":"2022-06-29T14:57:34.783599Z","shell.execute_reply.started":"2022-06-29T14:57:34.773147Z","shell.execute_reply":"2022-06-29T14:57:34.782439Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Figure 2. Log Likelihood","metadata":{}},{"cell_type":"markdown","source":"# Multi-Class Logistic Regression Classification on Iris Dataset","metadata":{}},{"cell_type":"code","source":"# Step 1: We will import the Iris Dataset\n\nimport pandas as pd\n\n# We  use the .read_csv command from the Pandas library\n# to store the dataset as dataframe type file.\n\ndataset= pd.read_csv('../input/iris-flower-dataset/IRIS.csv')\n\n# Reading the first 5 sample of the dataset using the \n# .head() command. \n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:34.785700Z","iopub.execute_input":"2022-06-29T14:57:34.786484Z","iopub.status.idle":"2022-06-29T14:57:34.836616Z","shell.execute_reply.started":"2022-06-29T14:57:34.786436Z","shell.execute_reply":"2022-06-29T14:57:34.835434Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Step 2: Separating Features(Independent Variable) and Labels(Dependent Variables)\n\n\n# The .iloc function is used to separate the \n# features and the labels into numpy arrays 'x' and 'y' respectively.\n\n\n# INQUIRY: WORKING OF .iloc(Part of data analysis)\n\n# Arguments for iloc= [rows, columns]\n\nx= dataset.iloc[:, 1:-1].values \n\ny= dataset.iloc[:, -1].values ","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:34.838571Z","iopub.execute_input":"2022-06-29T14:57:34.839050Z","iopub.status.idle":"2022-06-29T14:57:34.848258Z","shell.execute_reply.started":"2022-06-29T14:57:34.839005Z","shell.execute_reply":"2022-06-29T14:57:34.847139Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Printing total number of samples as an example for the \n# .iloc function. \":\" means all the rows/columns when \n# specified in the argument. \n\nprint(\"Total Samples: \",len(dataset.iloc[:]))","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:34.850117Z","iopub.execute_input":"2022-06-29T14:57:34.850880Z","iopub.status.idle":"2022-06-29T14:57:34.860726Z","shell.execute_reply.started":"2022-06-29T14:57:34.850831Z","shell.execute_reply":"2022-06-29T14:57:34.859616Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Step 3: Splitting Train and Test Data\n\n# We import the train_test_split function from \n# SciKit Learn(sklearn) library\n\nfrom sklearn.model_selection import train_test_split\n\n\n# The test is 20% of the samples and the train size is \n# 80% of the data.\n\nx_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.2, random_state= 0)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:34.862229Z","iopub.execute_input":"2022-06-29T14:57:34.863423Z","iopub.status.idle":"2022-06-29T14:57:36.069517Z","shell.execute_reply.started":"2022-06-29T14:57:34.863376Z","shell.execute_reply":"2022-06-29T14:57:36.068340Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Step 3: Scaling/ Normalizing the Data (Standardization)\n\n# This is performed to scale the values of the features \n# so that the values of the features range from -1 to 1. This \n# is important as some ML models including Logistic \n# regression are sensitive to if the data has been scaled or not.\n\n# The Standard Scalar\n\nfrom sklearn.preprocessing import StandardScaler\n\n# An instance of Standard Scaler known as 'sc' is created.\n\nsc= StandardScaler()\n\n# The fit_transform fits the scaler to the data AND\n# scales the training data.\n\nx_train = sc.fit_transform(x_train)\n\n# Why do we not use .fit_transform for x_test as it is separate \n# from x_train \n\nx_test= sc.transform(x_test) \n\nprint(x_train[:10])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:36.071907Z","iopub.execute_input":"2022-06-29T14:57:36.072280Z","iopub.status.idle":"2022-06-29T14:57:36.082214Z","shell.execute_reply.started":"2022-06-29T14:57:36.072248Z","shell.execute_reply":"2022-06-29T14:57:36.081429Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Step 4: Importing the Logistic Regression Model and Fitting the Training Data to the Model.\n\n# The Logistic Regression model is imported from \n# sklearn library.\n\nfrom sklearn.linear_model import LogisticRegression\n\n# An instance of the model known as 'classifier' is made\n# with input parameters where multi_class is specified \n# as 'ovr'. \n\n# By specifying the mulit_class paramter as 'ovr', The Logistic Regression model can \n# work in a multi-class scenario\n\nclassifier= LogisticRegression(multi_class='ovr', random_state=0)\n\nclassifier.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:57:36.084745Z","iopub.execute_input":"2022-06-29T14:57:36.085132Z","iopub.status.idle":"2022-06-29T14:57:36.216917Z","shell.execute_reply.started":"2022-06-29T14:57:36.085099Z","shell.execute_reply":"2022-06-29T14:57:36.215745Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Printing the number of samples\n\nprint(\"Testing Samples: \",len(x_train))","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:10:39.323423Z","iopub.execute_input":"2022-06-29T15:10:39.323842Z","iopub.status.idle":"2022-06-29T15:10:39.329709Z","shell.execute_reply.started":"2022-06-29T15:10:39.323810Z","shell.execute_reply":"2022-06-29T15:10:39.328609Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Step 5: Using the Model for Predicting Test Labels.\n\n# We import the confusion_matric and the accuracy_score function from the \n# sklearn.metric library. \n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# We then use the classifer to predict the test labels from the test features.\n\npredictions= classifier.predict(x_test)\n\ncm= confusion_matrix(predictions, y_test)\n\n# The Predictons and the Confusion Matfix are printed.  \n\nprint(cm)\n\nprint(predictions)\n\n# The accuracy_score function is used to calculate the \n# accuracy of the model in predicting the test labels\n\nprint(\"Model Test Accuracy(%): \",accuracy_score(predictions, y_test)*100)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:08:47.848417Z","iopub.execute_input":"2022-06-29T15:08:47.849082Z","iopub.status.idle":"2022-06-29T15:08:47.863156Z","shell.execute_reply.started":"2022-06-29T15:08:47.849038Z","shell.execute_reply":"2022-06-29T15:08:47.862012Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"i.e The accuracy of the model is therefore 90%. ","metadata":{}},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"In conclusion, the Logistic regression was thoeretically discussed, and then a Multi-Class Logistic Regression Model was built to classify species of plants based on the features of the plants shown. The Accuracy of the model was 90% on the test set as shown above.","metadata":{}}]}
